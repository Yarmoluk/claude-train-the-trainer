# Chapter 3: Workshop Design and Facilitation — Building Modular AI Training Sessions

## Learning Objectives

By the end of this chapter, you will be able to:

- Apply a modular workshop architecture that scales from 60-minute lunch sessions to full-day intensives
- Design training sessions with appropriate ratios of instruction, demonstration, guided practice, and independent application
- Facilitate AI training workshops using techniques specific to tool adoption contexts
- Anticipate and manage the four most common facilitation challenges in Claude training
- Create reusable session templates your organization can deploy without you

---

## Why AI Tool Training Requires Different Workshop Design

Most corporate training follows a predictable structure: slides, examples, quiz, done. That approach fails for AI tool training for three reasons.

**First, the tool behaves differently in different hands.** A learner cannot passively receive knowledge about Claude and then use it effectively. They must interact with it, encounter its variability, and develop judgment through practice. Workshops that are primarily informational produce informed non-users — people who understand Claude conceptually but do not use it.

**Second, the outputs are not binary.** Unlike software training where the answer is either right or wrong, Claude outputs exist on a quality spectrum. Learners need calibration — repeated exposure to outputs and explicit feedback about quality — not just instruction.

**Third, resistance is structural, not informational.** Many workshop participants arrive with anxiety, skepticism, or professional identity concerns about AI. These cannot be addressed with better slides. They require facilitation techniques that make practice feel safe and discovery feel normal.

This chapter gives you the design and facilitation tools to build workshops that actually change behavior.

---

## The Modular Workshop Architecture

The most resilient workshop design is modular — built from interchangeable components that can be assembled into sessions of different lengths without rebuilding from scratch.

### The Five Module Types

Every effective Claude training session draws from five module types in varying combinations:

**Module Type 1: Concept (10–20 min)**
Direct instruction on a specific concept. Used to introduce ideas that require explanation before practice. Keep these tight. More than 20 minutes of uninterrupted concept delivery loses most adult learners.

**Module Type 2: Demonstration (10–15 min)**
Trainer-led live interaction with Claude that shows a concept in action. The most important rule of demonstration: **run it live, not from screenshots.** Pre-recorded outputs remove variability and create false impressions of reliability. Live demonstration teaches learners how to handle unexpected outputs — a critical skill.

**Module Type 3: Guided Practice (20–30 min)**
Learners complete a structured task with a defined outcome while the trainer circulates and provides support. The task should be specific enough to prevent total paralysis but open enough to produce diverse outputs worth discussing.

**Module Type 4: Pair Exploration (15–25 min)**
Two learners work together on a task, talking through their decisions. This surfaces reasoning in ways solo practice does not. Pairs often catch each other's errors and develop richer prompt strategies through dialogue.

**Module Type 5: Debrief (10–20 min)**
Facilitated group discussion of what learners produced, what surprised them, and what they would do differently. The debrief is where learning consolidates. It is the most commonly under-resourced module type — trainers consistently budget too little time for it.

### Assembling Modules by Session Length

| Session Length | Recommended Assembly |
|---------------|---------------------|
| 45–60 minutes | 1 Concept + 1 Demonstration + 1 Guided Practice + Short Debrief |
| 90 minutes | 2 Concepts + 1 Demonstration + 1 Guided Practice + 1 Pair Exploration + Full Debrief |
| Half-day (3 hr) | 3–4 Concepts + 2 Demonstrations + 2 Guided Practices + 1 Pair Exploration + Extended Debrief |
| Full-day | Full sequence across Foundation → Application → Integration arc |

The key constraint is practice time. A workshop that spends more than 40% of its time on concept and demonstration is under-serving learners. Aim for at least 50% in active practice.

---

## Designing Learning Objectives That Work

Weak learning objectives produce weak workshops. The most common mistake is writing objectives that describe topics rather than behaviors.

**Weak (topic):** "Participants will learn about prompt engineering."

**Strong (behavior):** "Participants will be able to write a prompt that specifies role, context, and output format, and explain the function of each element."

Strong learning objectives have three characteristics:

1. **Observable action verb** — write, analyze, compare, demonstrate, construct, evaluate. Not: understand, learn, appreciate, be familiar with.
2. **Specific content** — "write a prompt using RICO elements" not "write prompts"
3. **Condition or standard** — what context, with what constraints, to what quality bar

Write objectives first, before content. Every piece of content, every activity, and every assessment question should connect to at least one objective. If you cannot map a training element to an objective, cut it.

---

## The Workshop Design Sequence

Follow this sequence when designing a new session:

**Step 1: Define the audience and their starting point**
Who are they? What do they already know? What resistance might they bring? What does success look like for them specifically?

**Step 2: Write 3–5 learning objectives**
Use observable action verbs. Cover the skills that will most change their behavior.

**Step 3: Select module types for each objective**
Typically: Concept to introduce, Demonstration to show, Practice to build, Debrief to consolidate.

**Step 4: Sequence and time**
Arrange modules in a logical progression. Budget time conservatively — activities always take longer than planned. Build in 15% buffer.

**Step 5: Design activities before selecting content**
Most trainers reverse this and create slides first. Design your activities first, then create the minimal supporting content those activities require.

**Step 6: Create a facilitation guide, not just slides**
The facilitation guide includes: timing for each section, anticipated learner questions and responses, instructions for activities, debrief questions, and transition statements. A well-made facilitation guide allows another trainer to deliver your workshop.

---

## Facilitation Techniques Specific to AI Tool Training

General facilitation skills apply, but Claude training has specific dynamics that require specific techniques.

### Technique 1: The Live Failure

The single most powerful thing you can do in a Claude training session is intentionally run a poor prompt and produce a bad output. Then run a better prompt on the same task. The contrast teaches more than any explanation.

Live failures also normalize the experience of getting disappointing outputs. Many learners have abandoned Claude after a few poor interactions. Seeing the trainer encounter and recover from a bad output reframes that experience: it is a skill problem, not a tool problem.

### Technique 2: Think-Aloud Demonstration

When demonstrating, narrate your reasoning explicitly. "I'm going to specify a role here because this is a specialized analysis — I want Claude thinking like a credit analyst, not a generalist. Now I'm adding context about our company because without it, Claude will give me generic advice..."

Think-aloud makes implicit expert reasoning visible to learners. Most prompt expertise is tacit; think-aloud is the tool that makes it explicit and transferable.

### Technique 3: Deliberate Variation

When demonstrating or running guided practice, encourage participants to try different approaches to the same task. Two people writing prompts for the same objective will produce different outputs — and both may be useful. Comparing variations teaches learners that there is no single correct prompt, and develops the calibration ability they need for independent use.

### Technique 4: The "What Would You Change?" Debrief

After any guided practice, before discussing what "should" have happened, ask learners: "What would you change about your prompt, knowing what you saw?" This debrief question externalizes learning — learners articulate their own insight rather than receiving it from the trainer.

### Technique 5: Anchor to Real Work

AI training that uses generic example tasks produces generic behavior change. Every exercise should be adaptable to the participant's actual work context. When possible, ask learners to substitute a real task from their role. "Use the same prompt structure we just practiced, but for a task you're actually working on this week."

---

## Managing Common Facilitation Challenges

### Challenge 1: The Skeptic Who Refuses to Engage

Some participants arrive convinced that AI is either overhyped, a threat, or inappropriate for their work. They may be vocal about this.

**Response:** Do not argue. Invite them to test their hypothesis. "Let's find out — pick a task you don't think Claude can help with, and we'll run it." Skeptics who engage, even critically, often become the most productive participants because they hold the output to a higher standard.

If the task genuinely doesn't work, acknowledge it: "That's a legitimate example of a use case that doesn't fit. What tasks are similar to this where you think it might work?" Honesty about limitations builds credibility.

### Challenge 2: The Expert Who Already Knows Everything

Some participants are already competent Claude users. They may become disengaged during foundational content.

**Response:** Recruit them. Give them the role of resident resource — others can ask them questions during activities. Offer them more advanced challenges. Frame the session as an opportunity to develop their ability to teach, not just to use.

### Challenge 3: The Participant Who Gets Bad Outputs and Shuts Down

When a learner gets a low-quality output from Claude, a common response is to conclude that the tool doesn't work and disengage. This is the critical intervention moment.

**Response:** Normalize and redirect. "This is actually a perfect example of what we're going to work on. Claude gave you what the prompt asked for — let's look at the prompt and figure out what it needs." Turn the failure into the teaching case.

### Challenge 4: The Technology Problem

Live demonstrations involve real technology that can fail, produce unexpected outputs, or behave in ways that derail the planned flow.

**Response:** Have a backup plan. For critical demonstrations, have the output saved locally in case the live demo fails. Practice narrating your way through unexpected outputs — "that's not what I was expecting, let me show you how I'd troubleshoot this" is itself a valuable teaching moment.

---

## Building Reusable Session Templates

A well-designed session template allows other trainers to deliver your workshop without rebuilding it. Templates should include:

**Session Brief**
- Target audience
- Learning objectives
- Prerequisites
- Required materials and setup
- Total time

**Facilitation Script**
- Module-by-module timing
- Opening framing (how to introduce the session)
- Transitions between modules
- Key talking points for each concept
- Questions to ask during debrief

**Activity Instructions**
- Setup instructions
- Participant instructions (written, suitable for printing or projecting)
- Sample outputs (good and poor) for calibration
- Common variations and how to handle them

**Troubleshooting Guide**
- Common participant questions and suggested responses
- Technical failure contingencies
- Facilitation challenges and interventions

---

## Exercise 1: Workshop Reverse Engineering

**Time:** 30 minutes
**Format:** Individual
**Materials:** Worksheet with workshop analysis framework

Select a Claude training session you have delivered or attended — or use the session outline below as a reference case. Map it against the modular architecture:

1. Identify each module type present and its duration
2. Calculate the ratio of instruction/demonstration to practice time
3. Identify the learning objectives (written or implicit)
4. List the facilitation techniques used
5. Identify one change you would make to improve learner practice time

Debrief with a partner: what would you keep? What would you change?

---

## Exercise 2: Design a 90-Minute Workshop

**Time:** 45 minutes design + 10 minutes peer review
**Format:** Individual design, pair review
**Materials:** Workshop design template

Design a 90-minute Claude training session for a specific audience of your choice (a real audience from your organization is best). Your design must include:

- 3 written learning objectives with observable action verbs
- A module sequence with timing for each segment
- At least 2 activities with written participant instructions
- 5 debrief questions for the closing discussion
- One facilitation challenge you anticipate and your planned response

Exchange designs with a partner. Review each other's design against the criteria: Are the objectives behavioral? Does practice time meet or exceed 50%? Can you identify the progression from concept to application?

---

## Key Takeaways

- AI tool training requires more practice time than informational training. A workshop that is more than 40% instruction is under-serving learners.
- The five module types — Concept, Demonstration, Guided Practice, Pair Exploration, and Debrief — are interchangeable components that can be assembled into sessions of any length.
- Write learning objectives before content. Every element of the workshop must connect to an objective.
- Facilitation techniques specific to AI training — live failures, think-aloud demonstration, deliberate variation — are more effective than general facilitation techniques for building hands-on skill.
- The debrief is the most under-resourced module type and the one where learning consolidates. Protect it aggressively when sessions run long.
- Reusable facilitation guides enable other trainers to deliver your work. Designing for reuse from the start creates organizational leverage.

---

*Next: Chapter 4 — Content Adaptation for Audiences*
